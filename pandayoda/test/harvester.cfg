#!/usr/bin/env python
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# http://www.apache.org/licenses/LICENSE-2.0
#
# Authors:
# - ..


#########################
#
# Master parameters
#

[master]

# user name of the daemon process
uname = benjamin

# group name of the daemon process
gname =  AtlasADSP

# logger name
loggername = harvester

# harvester id - unique id as registered also in panda server
harvester_id = ALCF_Theta



##########################
#
# Database parameters
#

[db]

# filename
database_filename = /projects/AtlasADSP/atlas/harvester/test.db

# verbose
verbose = True

# number of connections
nConnections = 10

# engine sqlite or mariadb
engine = sqlite

# user name
user = harvester

# password
password = ALCF_Theta 

# schema
schema = HARVESTER




##########################
#
# Panda Connection parameters
#

[pandacon]

# number of connections
nConnections = 5

# timeout
timeout = 180

# CA file
ca_cert = /projects/AtlasADSP/atlas/harvester/etc/pki/tls/certs/CERN-bundle-3.pem

# certificate
cert_file = /projects/AtlasADSP/atlas/harvester/globus/x509up_usathpc_gridproxy
#cert_file = /projects/AtlasADSP/atlas/harvester/globus/usathpc-robot-usercert.pem

# key
key_file = /projects/AtlasADSP/atlas/harvester/globus/x509up_usathpc_gridproxy
#key_file = /projects/AtlasADSP/atlas/harvester/globus/usathpc-robot-userkey.pem

# base URL via http
pandaURL = http://pandaserver.cern.ch:25080/server/panda

# base URL via https
pandaURLSSL = https://pandaserver.cern.ch:25443/server/panda

# base URL via proxy
pandaURLProxy = http://pandaserver.cern.ch:25080/server/panda

# verbose
verbose = True




##########################
#
# Queue Config parameters
#

[qconf]

# config file
configFile = /projects/AtlasADSP/atlas/harvester/examples/panda_queueconfig.json

# queue list : one queue name following a whitespace per line
queueList =
 ALCF_Theta





##########################
#
# Command manager parameters
#
[commandmanager]

# bulk size for panda server interactions
commands_bulk_size = 20

# sleep interval in sec
sleepTime = 5




##########################
#
# Job Fetcher parameters
#

[jobfetcher]

# number of threads
nThreads = 3

# number of queues to fetch jobs in one cycle
nQueues = 5

# max number of jobs per queue in one cycle
maxJobs = 500

# lookup interval in sec
lookupTime = 60

# sleep interval in sec
sleepTime = 60




##########################
#
# Propagator parameters
#

[propagator]

# number of threads
nThreads = 3

# max number of jobs to update in one cycle
maxJobs = 100

# number of jobs in bulk update
nJobsInBulk = 10

# max number of workers to update in one cycle
maxWorkers = 100

# number of workers in bulk update
nWorkersInBulk = 10

# lock interval in sec
lockInterval = 180

# update interval in sec
updateInterval = 1800

# sleep interval in sec
sleepTime = 60




##########################
#
# Preparator parameters
#

[preparator]

# number of threads
nThreads = 3

# max number of jobs to check in one cycle
maxJobsToCheck = 100

# max number of jobs to trigger in one cycle
maxJobsToTrigger = 100

# lock interval in sec
lockInterval = 180

# check interval in sec
checkInterval = 180

# trigger interval in sec
triggerInterval = 180

# sleep interval in sec
sleepTime = 60




##########################
#
# Submitter parameters
#

[submitter]

# number of threads
nThreads = 3

# max number of queues to try in one cycle
nQueues = 3

# interval for queue lookup
lookupTime = 60

# lock interval in sec
lockInterval = 180

# check interval in sec
checkInterval = 60

# sleep interval in sec
sleepTime = 60




##########################
#
# Monitor parameters
#

[monitor]

# number of threads
nThreads = 3

# max number of wokers per queue to try in one cycle
maxWorkers = 500

# lock interval in sec
lockInterval = 180

# check interval in sec
checkInterval = 120

# sleep interval in sec
sleepTime = 60




##########################
#
# Credential Manager parameters
#

[credmanager]

# module name
moduleName = pandaharvester.harvestercredmanager.proxy_cache_cred_manager

# class name
className = ProxyCacheCredManager

# cert file
certFile = /projects/AtlasADSP/atlas/harvester/globus/x509up_usathpc_vomsproxy

# voms
voms = atlas:/atlas/Role=production

# sleep interval in sec
sleepTime = 1800





##########################
#
# Stager parameters
#

[stager]

# number of threads
nThreads = 3

# max number of jobs to check in one cycle
maxJobsToCheck = 100

# max number of jobs to trigger in one cycle
maxJobsToTrigger = 100

# max number of jobs to zip in one cycle
maxJobsToZip = 100

# lock interval in sec
lockInterval = 180

# check interval in sec
checkInterval = 180

# trigger interval in sec
triggerInterval = 180

# sleep interval in sec
sleepTime = 60





##########################
#
# EventFeeder parameters
#

[eventfeeder]

# number of threads
nThreads = 3

# max number of workers per queue to try in one cycle
maxWorkers = 500

# lock interval in sec
lockInterval = 180

# sleep interval in sec
sleepTime = 60





##########################
#
# Cacher parameters
#

[cacher]

# one data following a white space per line
data =
 ddmendpoints_objectstores.json||http://atlas-agis-api.cern.ch/request/ddmendpoint/query/list/?json&state=ACTIVE&site_state=ACTIVE&preset=dict&json_pretty=1&type[]=OS_LOGS&type[]=OS_ES
 panda_queues.json||http://atlas-agis-api.cern.ch/request/pandaqueue/query/list/?json&preset=schedconf.all&vo_name=atlas
# refresh interval in minint
refreshInterval = 10

# sleep interval in sec
sleepTime = 60





##########################
#
# Payload interaction parameters
#

[payload_interaction]

# worker attributes
workerAttributesFile = worker_attributes.json

# job report
jobReportFile = jobReport.json

# event status dump file in json
eventStatusDumpJsonFile = event_status.dump.json

# event status dump file in xml
eventStatusDumpXmlFile = _event_status.dump

# job request
jobRequestFile = worker_requestjob.json

# job spec file
jobSpecFile = HPCJobs.json

# event request
eventRequestFile = worker_requestevents.json

# event ranges file
eventRangesFile = JobsEventRanges.json

# update events
updateEventsFile = worker_updateevents.json

# PFC for input files
xmlPoolCatalogFile = PoolFileCatalog_H.xml

# get PandaIDs
pandaIDsFile = worker_pandaids.json




##########################
#
# Front-end parameters
#

[frontend]

# port number
portNumber = 25080

# number of threads
nThreads = 10

# verbose
verbose = False

# type
type = simple





##########################
#
# Sweeper parameters
#

[sweeper]

# number of threads
nThreads = 3

# max number of workers per queue to try in one cycle
maxWorkers = 500

# check interval in sec
checkInterval = 180

# sleep interval in sec
sleepTime = 60

# duration in hours to keep finished workers
keepFinished = 24

# duration in hours to keep failed workers
keepFailed = 72

# duration in hours to keep cancelled workers
keepCancelled = 72
